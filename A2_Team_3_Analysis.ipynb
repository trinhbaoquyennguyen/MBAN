{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a79eb0-54f7-4a83-b435-e84e4c69c80b",
   "metadata": {
    "id": "c6a79eb0-54f7-4a83-b435-e84e4c69c80b"
   },
   "source": [
    "# Problem Statement\n",
    "\n",
    "The company is concerned about an increase in customer churn that could lead to a significant loss of revenue and market share. Failing to predict and prevent this customer turnover effectively will harm the company, both financially and reputationally. \n",
    "\n",
    "A prediction model must be developed to uncover the core causes of this churn and devise mitigation solutions before clients leave the company. The model is also capable of predicting whether or not future clients will leave the company or stay as clients, based on the customer dataset 'A2.csv'.\n",
    "\n",
    "Understanding why clients churn and what factors take place in order for clients to churn is important to analyze. \n",
    "\n",
    "The churn can be dependent on various factors, and it is important to identify them in order to minimize the churn in the future. The factors are then analyzed to conclude whether they cause a positive or negative impact. \n",
    "\n",
    "The trends identified can be used by upper-management to make informed decisions on how to best avoid customer churn in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e88be-fd10-49cb-b3b0-54a4cbc728e2",
   "metadata": {
    "id": "704e88be-fd10-49cb-b3b0-54a4cbc728e2"
   },
   "source": [
    "# Results\n",
    "During the design of the predictive model, it was discovered that Total charges (monthlycharges*tenure), estimated salary, month to month contract, no online security, no tech support, DSL internet service, no device protection and no online backup have the most predictive power in that order.\n",
    "\n",
    "However, the elimination of the other columns - has dependents, has no multiple lines, non-automatic payment, is senior citizen - lowers the prediction power of the model. This indicates that even though they are not the most important component of the cause for churn, they do have certain weight in it.\n",
    "\n",
    "Random Forest and Balanced Random Forest were the best perfoming models in the first iteration of the different models.\n",
    "\n",
    "In the second iteration, because the class imbalance in the training/testing split of the dataset was treated before running the different models, the Random Forest prediction model performed better and is therefore proposed to be used by upper management in their decision making.\n",
    "\n",
    "The Random Forest Predictive Model yielded the following results:\n",
    "\n",
    "- The results are presenting the performance metrics of a binary classification model, specifically a Random Forest model, on a dataset of 2953 instances. The model is predicting between two classes in terms of Churn, labeled 0 if the customer did not leave the company and 1 if the customer did leave the company.\n",
    "\n",
    "- Precision is the fraction of true positives (TP) out of all the positive predictions (TP + false positives (FP)). In this case, precision for ‘No Churn’  is 0.87, meaning that out of all the instances that the model predicted as class ‘No Churn’, 87% of them were, in fact, customers that didn't leave the company. Precision for ‘Churn’ is 0.89, meaning that out of all the instances that the model predicted as customers that churned, 89% of them were actually ‘Churn’.\n",
    "\n",
    "\n",
    "-\tRecall is the proportion of true positives (TP) out of all the actual positives (TP + false negatives (FN)). In this case, recall for ‘No Churn' is 0.90, indicating that out of all the instances that were actually ‘No Churn’, 90% of them were correctly detected by the model. Recall for ‘Churn’ is 0.86, meaning that out of all the instances that were ‘Churn’, 86% of them were correctly classified by the model.\n",
    "\n",
    "-\tA single metric that balances precision and recall is the F1-score, which is the harmonic mean of the two. The F1 score for \"No Churn\" and \"Churn\" are both 0.88. \n",
    "\n",
    "-\tAccuracy is the percentage of instances (TP + TN) that were successfully predicted out of all instances. In this instance, the model's overall accuracy was 0.88, which indicates that 88% of the cases in the dataset were properly identified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f26ae-2c91-4354-8f4a-56d645b862a1",
   "metadata": {
    "id": "8b5f26ae-2c91-4354-8f4a-56d645b862a1"
   },
   "source": [
    "# Assumptions made\n",
    "\n",
    "- The data provided is accurate.\n",
    "- The unit for tenure is indicated by months.\n",
    "- The current month’s charge is not included in the total charges.\n",
    "- There are outliers in the data, for example estimated salary has a value 11.58.\n",
    "- Considering senior citizens are people of the age above 65.\n",
    "- The values for charges are calculated with extra services included and taxes which are fixed for each month.\n",
    "- Estimated Salary has been calculated based on feedback forms completed by customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd47a24-6b1d-4abc-9ecb-6b620af72cf8",
   "metadata": {
    "id": "8bd47a24-6b1d-4abc-9ecb-6b620af72cf8"
   },
   "source": [
    "# Limitations\n",
    "\n",
    "- The model cannot provide a best practice to prevent customer churn; that is a business decision to be made by a different team withi+n the company. \n",
    "- There is no supporting data on describing the potential cause of churn. \n",
    "- The trends observed during the analysis are isolated and cannot be used by themselves to explain the churn rate. \n",
    "- There is a lack of data on how the added services are sold, as well as pricing policies. If the company were to make the marketing data available to this team the predictive model could be improved and expanded to contemplate the causes for churn in detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59bd86-42f9-40fa-8389-c564b303ad60",
   "metadata": {
    "id": "ee59bd86-42f9-40fa-8389-c564b303ad60"
   },
   "source": [
    "# Data\n",
    "\n",
    "The dataset 'A2.csv' was provided by the company because it contains customer data which will aid in the analysis of the churn.\n",
    "# EDA: Variables & Description\n",
    "### Continuous\n",
    "\n",
    "- `Tenure` : Time as the customer of the company, expressed in months.\n",
    "- `Total Charges` : Total amount paid by the end of tenure.\n",
    "- `Credit Score` : Credit score for each customer (No source).\n",
    "- `Estimated Salary` : Estimated based salary for each customer.\n",
    "- `Monthly Charges` : Per month charges calculated for each customer per service.\n",
    "- `Charge` : Expenses calculated for the current month for each customer.\n",
    "\n",
    "### Categorical\n",
    "\n",
    "- `Gender` : Identifies Female = 0 and Male = 1\n",
    "- `Senior Citizen` : Age over 65; identifies Yes = 1 and No = 0.\n",
    "- `Partner` : Cohabitant; identifies Yes = 1 and No = 0.\n",
    "- `Phone Service` : Phone service included in contract; identifies Yes = 1 and No = 0.\n",
    "- `Multiple Lines` : More than 1 phone line included in the contract.\n",
    "- `Internet Services` : Internet service included in contract.\n",
    "- `Online Security` : Online Security included in contract.\n",
    "- `Online Backup` : Online Backup included in contract.\n",
    "- `Device Protection` : Device Protection included in contract.\n",
    "- `Tech Support` : Tech Support included in contract.\n",
    "- `Streaming TV` : Streaming TV service included in contract.\n",
    "- `Streaming Movies` : Streaming Movies service included in contract.\n",
    "- `Contract` : Duration of the contract.\n",
    "- `Paperless Billing` : Electronic billing activated.\n",
    "- `Churn` : Customers stopped subscribing to the services.\n",
    "- `Geography` : Countries where the customers are located.\n",
    "- `Dependants` : Customers have people depending on them.\n",
    "- `Payment Method` : Customer's payment mode.\n",
    "\n",
    "\n",
    "### Personal Identification Information (PII)\n",
    "- `Surname`\n",
    "- `Customer ID`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hs_51PjmNh9F",
   "metadata": {
    "id": "hs_51PjmNh9F"
   },
   "source": [
    "If the packages have never been installed in the terminal, these are the necessary codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mue3HVCWIWY6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "Mue3HVCWIWY6",
    "outputId": "7f56225b-b0a0-4591-935c-011ecd7a2f0a"
   },
   "outputs": [],
   "source": [
    "# pip install xgboost\n",
    "# pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-LJ_UmL3Esu-",
   "metadata": {
    "id": "-LJ_UmL3Esu-"
   },
   "outputs": [],
   "source": [
    "# Importing all the relevant libraries for this analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from sklearn.impute import KNNImputer\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#sklearn modules for Model Selection:\n",
    "from sklearn import linear_model, neighbors\n",
    "from sklearn import naive_bayes, ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "#sklearn modules for Model Evaluation & Improvement:\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import make_scorer, recall_score, log_loss\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RJM3PbmJFChR",
   "metadata": {
    "id": "RJM3PbmJFChR"
   },
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "data = pd.read_csv('A2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7HrXMDhuF-54",
   "metadata": {
    "id": "7HrXMDhuF-54"
   },
   "outputs": [],
   "source": [
    "# Preliminar exploration of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C22egII8GI22",
   "metadata": {
    "id": "C22egII8GI22"
   },
   "outputs": [],
   "source": [
    "# Print the name of the columns\n",
    "for col in data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sXkdQRFuGrUF",
   "metadata": {
    "id": "sXkdQRFuGrUF"
   },
   "outputs": [],
   "source": [
    "# Calculated the % of missing values per column\n",
    "for i in data.columns:\n",
    "    n_miss = data[[i]].isna().sum().sum()\n",
    "    #perc = round(n_miss/gdp_gni_ne.shape[0]*100,2)\n",
    "    perc = round(n_miss / len(data) * 100, 2)\n",
    "    print(f'Missing values for \\033[1m{i}\\033[0m is {perc}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2m4oCa8cHK9l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "2m4oCa8cHK9l",
    "outputId": "5e1f8b0a-9678-458a-b4ab-c4fbfac369d6"
   },
   "outputs": [],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9L_RqKkqMaKD",
   "metadata": {
    "id": "9L_RqKkqMaKD"
   },
   "source": [
    "After understanding how many values were empty in the dataset, a plan was devised to treat them. \n",
    "\n",
    "Dropping all null values was not a possibility since the total number of observations that would have been dropped represented nearly 25% of the dataset. \n",
    "\n",
    "Therefore, null values were filled with the mode, the most repeated value, in the categorical variables.\n",
    "\n",
    "Null values present in continuous variables were filled with the median so that the results wouldn't be skewed in anyway by the treatment process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rmKKnL7OHUIU",
   "metadata": {
    "id": "rmKKnL7OHUIU"
   },
   "outputs": [],
   "source": [
    "# Finding the unique values in the columns\n",
    "data[\"PaymentMethod\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wWrszTUZHeJd",
   "metadata": {
    "id": "wWrszTUZHeJd"
   },
   "outputs": [],
   "source": [
    "data[\"Contract\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KR6uzSr-Hm_T",
   "metadata": {
    "id": "KR6uzSr-Hm_T"
   },
   "outputs": [],
   "source": [
    "data[\"Contract\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89IBjb2AHpvF",
   "metadata": {
    "id": "89IBjb2AHpvF"
   },
   "outputs": [],
   "source": [
    "data[\"Churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qDirRoCSOqEN",
   "metadata": {
    "id": "qDirRoCSOqEN"
   },
   "source": [
    "An imputation was used to fill the NA values in the columns Senior Citizen, Tenure, Credit Score, Estimated Salary, Monthly Charges and Charge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69AFT0HrHrrW",
   "metadata": {
    "id": "69AFT0HrHrrW"
   },
   "outputs": [],
   "source": [
    "# Imputation to deal with missing values\n",
    "data_list = ['SeniorCitizen','tenure', 'CreditScore', 'EstimatedSalary', 'MonthlyCharges', 'Charge' ]\n",
    "data_nv = data[data_list]\n",
    "impKNN = KNNImputer(n_neighbors=10)\n",
    "newval = impKNN.fit_transform(data_nv)\n",
    "data2 = pd.DataFrame(newval, columns=data_list, index = data_nv.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EuzGMNpXHtj5",
   "metadata": {
    "id": "EuzGMNpXHtj5"
   },
   "outputs": [],
   "source": [
    "# Confirming we dont have any missing values now\n",
    "for i in data2.columns:\n",
    "    n_miss = data2[[i]].isna().sum().sum()\n",
    "    #perc = round(n_miss/gdp_gni_ne.shape[0]*100,2)\n",
    "    perc = round(n_miss/len(data2)*100,2)\n",
    "    print(f'Missing values for \\033[1m{i}\\033[0m is {perc}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eZB8F8EHwYo",
   "metadata": {
    "id": "3eZB8F8EHwYo"
   },
   "outputs": [],
   "source": [
    "# Fill NaNs with mode for categorical variables\n",
    "data3 = data.copy()\n",
    "for column in data3.columns:\n",
    "    data3[column].fillna(data3[column].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Aw9ZJZVH8N9",
   "metadata": {
    "id": "-Aw9ZJZVH8N9"
   },
   "outputs": [],
   "source": [
    "data3['PhoneService'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FFEDwywTH87R",
   "metadata": {
    "id": "FFEDwywTH87R"
   },
   "outputs": [],
   "source": [
    "# Confirming the treatment of NA values\n",
    "for i in data3.columns:\n",
    "    n_miss = data3[[i]].isna().sum().sum()\n",
    "    #perc = round(n_miss/gdp_gni_ne.shape[0]*100,2)\n",
    "    perc = round(n_miss/len(data3)*100,2)\n",
    "    print(f'Missing values for \\033[1m{i}\\033[0m is {perc}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MW51gyfFH-nC",
   "metadata": {
    "id": "MW51gyfFH-nC"
   },
   "outputs": [],
   "source": [
    "# After treating NA values remerge the datasets in one dataset\n",
    "data_fin = pd.merge(data2, data3, left_index = True, right_index = True)\n",
    "data_fin = data_fin[['gender', 'SeniorCitizen_y','Partner','tenure_y','PhoneService', 'MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract','PaperlessBilling','TotalCharges','Churn','Geography','CreditScore_y','EstimatedSalary_y','MonthlyCharges_y','customerID','Dependents','PaymentMethod','Charge_y']]\n",
    "data_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j17ik5jqIBIx",
   "metadata": {
    "id": "j17ik5jqIBIx"
   },
   "outputs": [],
   "source": [
    "# Confirm the columns inside dataset\n",
    "for col in data_fin.columns:\n",
    "  print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b5dcb3-8ca6-446d-a904-30b8716f5afe",
   "metadata": {
    "id": "33b5dcb3-8ca6-446d-a904-30b8716f5afe"
   },
   "source": [
    "# Problem Solving\n",
    "\n",
    "- The problem solving began with a data preparation process where the data was cleaned to identify and discard errors, incorrect, and missing values.\n",
    "- The missing values were replaced by the mode or median of the variables to interpret and calculate efficiently.\n",
    "- The categorical values were transformed into boolean variables.\n",
    "- The cleaned data was then ready to be analyzed and interpreted to understand trends in the dataset.\n",
    "- In order to retain variables, proportion was plotted by calculating it for each variable against churn.\n",
    "- For every iteration, each regression model was executed to generate results.\n",
    "- The best performing model was selected to finalize the predictive model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w0CZIBViIDQ9",
   "metadata": {
    "id": "w0CZIBViIDQ9"
   },
   "outputs": [],
   "source": [
    "# Rename columns for readability\n",
    "data_fin.rename(columns={\n",
    "    'SeniorCitizen_y': 'SeniorCitizen',\n",
    "    'tenure_y': 'tenure',\n",
    "    'CreditScore_y': 'CreditScore',\n",
    "    'EstimatedSalary_y': 'EstimatedSalary',\n",
    "    'MonthlyCharges_y': 'MonthlyCharges',\n",
    "    'Charge_y': 'Charge'\n",
    "},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IxrTQPzCIFjl",
   "metadata": {
    "id": "IxrTQPzCIFjl"
   },
   "outputs": [],
   "source": [
    "# Convert Senior Citizen column to interger\n",
    "data_fin['SeniorCitizen'] = data_fin['SeniorCitizen'].astype(int)\n",
    "data_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9VdH2U6HIJYX",
   "metadata": {
    "id": "9VdH2U6HIJYX"
   },
   "outputs": [],
   "source": [
    "#  Plot of counts of values in columns\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 7), sharey=True)\n",
    "sns.countplot(\"gender\", data=data_fin, ax=axes[0,0])\n",
    "sns.countplot(\"SeniorCitizen\", data=data_fin, ax=axes[0,1])\n",
    "sns.countplot(\"Partner\", data=data_fin, ax=axes[0,2])\n",
    "sns.countplot(\"Dependents\", data=data_fin, ax=axes[1,0])\n",
    "sns.countplot(\"PhoneService\", data=data_fin, ax=axes[1,1])\n",
    "sns.countplot(\"PaperlessBilling\", data=data_fin, ax=axes[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "epwb1bl7Iq_L",
   "metadata": {
    "id": "epwb1bl7Iq_L"
   },
   "outputs": [],
   "source": [
    "# Transform 'Churn' into a boolean\n",
    "data_fin_0 = data_fin.copy()\n",
    "churn_numeric = {'Yes':1, 'No':0}\n",
    "data_fin_0.Churn.replace(churn_numeric, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kv-41f88RoY6",
   "metadata": {
    "id": "kv-41f88RoY6"
   },
   "source": [
    "Tables were created to see the proportion of customers that churned for each variable. \n",
    "\n",
    "Whenever the proportions were very similar for 'yes' or 'no' churn, a note was made to possibly drop the columns during the model creation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r8Ts_kPXIt6n",
   "metadata": {
    "id": "r8Ts_kPXIt6n"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Gender\n",
    "data_fin_0[['gender','Churn']].groupby(['gender']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4x0c4iyxIvxH",
   "metadata": {
    "id": "4x0c4iyxIvxH"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Multiple Line\n",
    "data_fin_0[['MultipleLines','Churn']].groupby(['MultipleLines']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R3SAcpmjIxfk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "R3SAcpmjIxfk",
    "outputId": "e25abacf-df41-40ea-a77c-0275ae4ff4f8"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Senior Citizen\n",
    "data_fin_0[['SeniorCitizen','Churn']].groupby(['SeniorCitizen']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NBeDw8mHIzXQ",
   "metadata": {
    "id": "NBeDw8mHIzXQ"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Partner\n",
    "data_fin_0[['Partner','Churn']].groupby(['Partner']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fp1jVbjcI1GO",
   "metadata": {
    "id": "Fp1jVbjcI1GO"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Phone Service\n",
    "data_fin_0[['PhoneService','Churn']].groupby(['PhoneService']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QQ6gQcfcI2cA",
   "metadata": {
    "id": "QQ6gQcfcI2cA"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Multiple Line\n",
    "data_fin_0[['MultipleLines','Churn']].groupby(['MultipleLines']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PJk-3ImmI4Ne",
   "metadata": {
    "id": "PJk-3ImmI4Ne"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Online Security\n",
    "data_fin_0[['OnlineSecurity','Churn']].groupby(['OnlineSecurity']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R3OIleU0I6UM",
   "metadata": {
    "id": "R3OIleU0I6UM"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Online Backup\n",
    "data_fin_0[['OnlineBackup','Churn']].groupby(['OnlineBackup']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nw3cQOTfI7zO",
   "metadata": {
    "id": "nw3cQOTfI7zO"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Device Protection\n",
    "data_fin_0[['DeviceProtection','Churn']].groupby(['DeviceProtection']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X_mrt000I9XD",
   "metadata": {
    "id": "X_mrt000I9XD"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Tech Support\n",
    "data_fin_0[['TechSupport','Churn']].groupby(['TechSupport']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qS1TwDvcI_Q5",
   "metadata": {
    "id": "qS1TwDvcI_Q5"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by StreamingTv\n",
    "data_fin_0[['StreamingTV','Churn']].groupby(['StreamingTV']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EOHAt544JBDO",
   "metadata": {
    "id": "EOHAt544JBDO"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Streaming Movies\n",
    "data_fin_0[['StreamingMovies','Churn']].groupby(['StreamingMovies']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CqOm4_j4JCwv",
   "metadata": {
    "id": "CqOm4_j4JCwv"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Contract\n",
    "data_fin_0[['Contract','Churn']].groupby(['Contract']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9VSBvgaJEfy",
   "metadata": {
    "id": "e9VSBvgaJEfy"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by PaperlessBilling\n",
    "data_fin_0[['PaperlessBilling','Churn']].groupby(['PaperlessBilling']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k13mADTYJGDz",
   "metadata": {
    "id": "k13mADTYJGDz"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Geography\n",
    "data_fin_0[['Geography','Churn']].groupby(['Geography']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "De6nYvJaJHvL",
   "metadata": {
    "id": "De6nYvJaJHvL"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Dependents\n",
    "data_fin_0[['Dependents','Churn']].groupby(['Dependents']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y9jIdz0tJKXl",
   "metadata": {
    "id": "Y9jIdz0tJKXl"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by Payment Method\n",
    "data_fin_0[['PaymentMethod','Churn']].groupby(['PaymentMethod']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eH3oxkwUJMGf",
   "metadata": {
    "id": "eH3oxkwUJMGf"
   },
   "outputs": [],
   "source": [
    "# Proportion of Churn by tTenure, Monthly Charges, Credit Score, & Estimated Salary\n",
    "data_fin_0[['tenure','MonthlyCharges','CreditScore','EstimatedSalary','Churn']].groupby('Churn').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WpmBB9sfJN6-",
   "metadata": {
    "id": "WpmBB9sfJN6-"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualization of the Churn by Senior Citizen\n",
    "%matplotlib inline\n",
    "pd.crosstab(data_fin_0.SeniorCitizen,data_fin_0.Churn).plot(kind='bar')\n",
    "plt.title('Churn by SenCit')\n",
    "plt.xlabel('SenCit')\n",
    "plt.ylabel('Churn')\n",
    "plt.savefig('churn_sencit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1sJIJfCJP0l",
   "metadata": {
    "id": "f1sJIJfCJP0l"
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe with the variables that were kept for the model\n",
    "data_fin_1 = data_fin_0[[\n",
    "    'SeniorCitizen', 'Partner', 'tenure', 'MultipleLines', 'InternetService',\n",
    "    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "    'Contract', 'EstimatedSalary', 'MonthlyCharges', 'Dependents',\n",
    "    'PaymentMethod', 'Churn'\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CuVNfAP-JR2G",
   "metadata": {
    "id": "CuVNfAP-JR2G"
   },
   "outputs": [],
   "source": [
    "# Confirmation of new dataframe\n",
    "for col in data_fin_1:\n",
    "  print(data_fin_1[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xX4UkEwTJTt6",
   "metadata": {
    "id": "xX4UkEwTJTt6"
   },
   "outputs": [],
   "source": [
    "# Split between X variables and y variables\n",
    "x_var = [\n",
    "    'SeniorCitizen', 'Partner', 'tenure', 'MultipleLines', 'InternetService',\n",
    "    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "    'Contract', 'EstimatedSalary', 'MonthlyCharges', 'Dependents',\n",
    "    'PaymentMethod'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sAcamXGpJV08",
   "metadata": {
    "id": "sAcamXGpJV08"
   },
   "outputs": [],
   "source": [
    "y_data = data_fin_1.loc[ : , 'Churn'] # y is always churn\n",
    "x_data = data_fin_1.loc[ : , x_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BHLqRdziJX2V",
   "metadata": {
    "id": "BHLqRdziJX2V"
   },
   "outputs": [],
   "source": [
    "s = (x_data.dtypes == 'object')\n",
    "object_cols = list(s[s].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84kdF9wTJZbB",
   "metadata": {
    "id": "84kdF9wTJZbB"
   },
   "outputs": [],
   "source": [
    "# If present = 1 if not present = 0\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "OH_cols = pd.DataFrame(OH_encoder.fit_transform(x_data[object_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Wy0q5kkJbZt",
   "metadata": {
    "id": "2Wy0q5kkJbZt"
   },
   "outputs": [],
   "source": [
    "OH_cols.index = x_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1wNq6CbkJdJM",
   "metadata": {
    "id": "1wNq6CbkJdJM"
   },
   "outputs": [],
   "source": [
    "OH_cols.set_axis(np.concatenate(OH_encoder.categories_), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JCNfnA1YJe-C",
   "metadata": {
    "id": "JCNfnA1YJe-C"
   },
   "outputs": [],
   "source": [
    "num_X = x_data.drop(object_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4O4B9KSbJgS_",
   "metadata": {
    "id": "4O4B9KSbJgS_"
   },
   "outputs": [],
   "source": [
    "OH_X = pd.concat([num_X, OH_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gn7PosISJhr5",
   "metadata": {
    "id": "Gn7PosISJhr5"
   },
   "outputs": [],
   "source": [
    "OH_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o8NpncvNJjNL",
   "metadata": {
    "id": "o8NpncvNJjNL"
   },
   "outputs": [],
   "source": [
    "col_labels = OH_X.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C98T8MRKUDbC",
   "metadata": {
    "id": "C98T8MRKUDbC"
   },
   "outputs": [],
   "source": [
    "# Name the columns\n",
    "col_labels[0] = \"is senior citizen\"\n",
    "col_labels[1] = \"tenure\"\n",
    "col_labels[2] = \"estimated salary\"\n",
    "col_labels[3] = \"monthly charges\"\n",
    "col_labels[4] = \"has no partner\"\n",
    "col_labels[5] = \"has partner\"\n",
    "col_labels[6] = \"has no multiple lines\"\n",
    "col_labels[7] = \"no phone service (multiple lines)\"\n",
    "col_labels[8] = \"has multiple lines\"\n",
    "col_labels[9] = \"DSL internet service\"\n",
    "col_labels[10] = \"fiber optic internet service\"\n",
    "col_labels[11] = \"no internet service (internet service)\"\n",
    "col_labels[12] = \"no online security\"\n",
    "col_labels[13] = \"no internet service (online security)\"\n",
    "col_labels[14] = \"has online security\"\n",
    "col_labels[15] = \"no online backup\"\n",
    "col_labels[16] = \"no internet service (online backup)\"\n",
    "col_labels[17] = \"has online backup\"\n",
    "col_labels[18] = \"no device protection\"\n",
    "col_labels[19] = \"no internet service (device protection)\"\n",
    "col_labels[20] = \"has device protection\"\n",
    "col_labels[21] = \"no tech support\"\n",
    "col_labels[22] = \"no internet service (tech support)\"\n",
    "col_labels[23] = \"has tech support\"\n",
    "col_labels[24] = \"month-to-month contract\"\n",
    "col_labels[25] = \"one-year contract\"\n",
    "col_labels[26] = \"two-year contract\"\n",
    "col_labels[27] = \"no dependents\"\n",
    "col_labels[28] = \"has dependents\"\n",
    "col_labels[29] = \"bank transfer (automatic)\"\n",
    "col_labels[30] = \"credit card (automatic)\"\n",
    "col_labels[31] = \"electronic check\"\n",
    "col_labels[32] = \"mailed check\"\n",
    "\n",
    "OH_X.columns = col_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1zkVXx17JlZh",
   "metadata": {
    "id": "1zkVXx17JlZh"
   },
   "outputs": [],
   "source": [
    "# Confirm name changes to columns\n",
    "full_data = pd.merge(OH_X, y_data, left_index = True, right_index = True)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bECDj-_Jnkv",
   "metadata": {
    "id": "5bECDj-_Jnkv"
   },
   "outputs": [],
   "source": [
    "# Heatmap of the correlation between the variables\n",
    "# Correlation above 0.5 or below -0.5 coefficient are shown\n",
    "# To consider what variables to drop\n",
    "def get_heatmap(dataframe):\n",
    "\n",
    "  corr = dataframe.corr()\n",
    "  plt.figure(figsize=(20, 15))\n",
    "\n",
    "  # Generate a mask for the upper triangle\n",
    "  mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "  # Only show the strong correlations\n",
    "  sns.heatmap(corr[(corr >= 0.5) | (corr <= -0.5)],\n",
    "              cmap='viridis',\n",
    "              mask=mask,\n",
    "              vmax=1.0,\n",
    "              vmin=-1.0,\n",
    "              linewidths=0.1,\n",
    "              annot=True,\n",
    "              annot_kws={\"size\": 8},\n",
    "              square=True)\n",
    "  \n",
    "get_heatmap(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MnDaLmoUJqMh",
   "metadata": {
    "id": "MnDaLmoUJqMh"
   },
   "outputs": [],
   "source": [
    "# Calculate Variance Inflation Factor, those with high values are dropped\n",
    "def compute_vif(considered_features):\n",
    "    \n",
    "    X = full_data[considered_features]\n",
    "    # the calculation of variance inflation requires a constant\n",
    "    X['intercept'] = 1\n",
    "    \n",
    "    # create dataframe to store vif values\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Variable\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif = vif[vif['Variable']!='intercept']\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uaXf23bFJszz",
   "metadata": {
    "id": "uaXf23bFJszz"
   },
   "outputs": [],
   "source": [
    "# features to consider removing\n",
    "considered_features = ['monthly charges', 'no internet service (internet service)', 'no online security', 'no internet service (online security)', 'no internet service (online backup)', 'no internet service (device protection)', 'no tech support', 'no internet service (tech support)']\n",
    "\n",
    "# compute vif \n",
    "compute_vif(considered_features).sort_values('VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5laBuqJvCI",
   "metadata": {
    "id": "df5laBuqJvCI"
   },
   "outputs": [],
   "source": [
    "# create dataset with dropped values\n",
    "\n",
    "list2 = ['no internet service (tech support)','no internet service (online backup)', 'no internet service (online security)', 'no internet service (internet service)', 'no internet service (device protection)']\n",
    "\n",
    "for i in list2:\n",
    "  if i in considered_features:\n",
    "    considered_features.remove(i)\n",
    "\n",
    "print(considered_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zUgp7gwgJxQj",
   "metadata": {
    "id": "zUgp7gwgJxQj"
   },
   "outputs": [],
   "source": [
    "# Confirm values of VIF\n",
    "compute_vif(considered_features).sort_values('VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SoQSVaDeJyyB",
   "metadata": {
    "id": "SoQSVaDeJyyB"
   },
   "outputs": [],
   "source": [
    "# Columns to drop in the creation of the model\n",
    "full_data_fs = full_data.drop(['no internet service (tech support)','no internet service (online backup)','no internet service (online security)','no internet service (internet service)','no internet service (device protection)','has no partner','no dependents'],axis=1)\n",
    "\n",
    "full_data_fs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NoFxSNHEJ0hI",
   "metadata": {
    "id": "NoFxSNHEJ0hI"
   },
   "outputs": [],
   "source": [
    "# Business Decision to drop columns\n",
    "to_remove = ['has partner', 'no phone service (multiple lines)',\n",
    "    'has multiple lines', 'fiber optic internet service',\n",
    "    'no internet service (internet service)', 'has online security',\n",
    "    'no internet service (online security)', 'has online backup',\n",
    "    'no internet service (online backup)',\n",
    "    'no internet service (device protection)', 'has device protection',\n",
    "    'no internet service (tech support)', 'has tech support',\n",
    "    'one-year contract', 'two-year contract', 'no dependents'\n",
    "]\n",
    "\n",
    "\n",
    "for i in to_remove:\n",
    "    for col in full_data_fs:\n",
    "        if i in col:\n",
    "            full_data_fs.drop(col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i5vdKZW0J3cf",
   "metadata": {
    "id": "i5vdKZW0J3cf"
   },
   "outputs": [],
   "source": [
    "# Confirm column drop\n",
    "full_data_fs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4lbyBXOlViz_",
   "metadata": {
    "id": "4lbyBXOlViz_"
   },
   "source": [
    "An initial training and testing dataset was created to conduct the test and training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WbKalGl1J5gB",
   "metadata": {
    "id": "WbKalGl1J5gB"
   },
   "outputs": [],
   "source": [
    "x_data = full_data_fs.drop('Churn',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u95nYNEDJ7UN",
   "metadata": {
    "id": "u95nYNEDJ7UN"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.30, random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rZgxo5pYV8Ik",
   "metadata": {
    "id": "rZgxo5pYV8Ik"
   },
   "source": [
    "The differents models that were tested in this analysis were:\n",
    "- Random Forest\n",
    "- Balanced Randon Forest\n",
    "- Logarythmic Regression\n",
    "- Extreme Gradient Boosting\n",
    "- K-Nearest Neighbors Algorithm \n",
    "- Gaussian Mixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ihVR9Mv8J87k",
   "metadata": {
    "id": "ihVR9Mv8J87k"
   },
   "outputs": [],
   "source": [
    "# Different models were run\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.30, random_state=53)\n",
    "\n",
    "print('RF') # Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 53)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Balanced RF') # Balanced Randon Forest\n",
    "\n",
    "brf = BalancedRandomForestClassifier(random_state = 53)\n",
    "brf.fit(X_train, y_train)\n",
    "y_pred = brf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('LOGREG') # Logarythmic Regression\n",
    "\n",
    "logreg = LogisticRegression(random_state = 53)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('XGB') # Extreme Gradient Boosting\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('KNN') # K-Nearest Neighbors Algorithm \n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Gaussian') # Gaussian Mixture\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XW4ACk3-KACw",
   "metadata": {
    "id": "XW4ACk3-KACw"
   },
   "outputs": [],
   "source": [
    "# Feature Importance is calculated\n",
    "# Weight how much of a predictive power each variable has\n",
    "importances = list(rf.feature_importances_)\n",
    "col_labels = x_data.columns.values.tolist()\n",
    "\n",
    "dict_test = {\"label\":col_labels,\"importances\":importances}\n",
    "\n",
    "df_test = pd.DataFrame(dict_test, columns=['label','importances'])\n",
    "\n",
    "df_test.sort_values(by=['importances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VYEzV7MOKDCO",
   "metadata": {
    "id": "VYEzV7MOKDCO"
   },
   "outputs": [],
   "source": [
    "#Create a heat map of the correlation between the variables\n",
    "def get_heatmap(dataframe):\n",
    "\n",
    "  corr = dataframe.corr()\n",
    "  plt.figure(figsize=(20, 15))\n",
    "\n",
    "  # Generate a mask for the upper triangle\n",
    "  mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "  # Only show the strong correlations\n",
    "  sns.heatmap(corr[(corr >= 0.5) | (corr <= -0.5)],\n",
    "              cmap='viridis',\n",
    "              mask=mask,\n",
    "              vmax=1.0,\n",
    "              vmin=-1.0,\n",
    "              linewidths=0.1,\n",
    "              annot=True,\n",
    "              annot_kws={\"size\": 8},\n",
    "              square=True)\n",
    "  \n",
    "get_heatmap(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dXpkIHyCKFUO",
   "metadata": {
    "id": "dXpkIHyCKFUO"
   },
   "outputs": [],
   "source": [
    "# Transform  all payment methods to  non automatic payment yes =1 no =0\n",
    "x_data[\"non-automatic payment\"] = np.where((x_data['electronic check'] == 1) \n",
    "                                             | (x_data['mailed check'] == 1),\n",
    "                                             1, 0)\n",
    "\n",
    "x_data.drop('electronic check', axis=1, inplace=True)\n",
    "x_data.drop('bank transfer (automatic)', axis=1, inplace=True)\n",
    "x_data.drop('credit card (automatic)', axis=1, inplace=True)\n",
    "x_data.drop('mailed check', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BdlgTtzZKHmo",
   "metadata": {
    "id": "BdlgTtzZKHmo"
   },
   "outputs": [],
   "source": [
    "# Confirm changes done in the dataset\n",
    "x_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LXPtbikYKJ81",
   "metadata": {
    "id": "LXPtbikYKJ81"
   },
   "outputs": [],
   "source": [
    "# Create a combined variable of Tenure and Monthly charges, named Total Charges\n",
    "x_data['total charges'] = x_data['tenure'] * x_data['monthly charges']\n",
    "x_data.drop('tenure',axis=1,inplace=True) # drop of original column\n",
    "x_data.drop('monthly charges',axis=1,inplace=True) # drop of original column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1n25ZradapWs",
   "metadata": {
    "id": "1n25ZradapWs"
   },
   "source": [
    "Another training and testing dataset was created to retest the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q98GUehqKMFQ",
   "metadata": {
    "id": "q98GUehqKMFQ"
   },
   "outputs": [],
   "source": [
    "# Instantiating of Synthetic Minority Over-sampling Technique was used to approach\n",
    "# construction of classifiers an imbalanced dataset\n",
    "\n",
    "sm = SMOTE(random_state=53)\n",
    "X_train, y_train = sm.fit_resample(x_data, y_data) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=53)\n",
    "\n",
    "print('RF') # Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 53)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('BRF') # Balanced Randon Forest\n",
    "\n",
    "brf = BalancedRandomForestClassifier(random_state = 53)\n",
    "brf.fit(X_train, y_train)\n",
    "y_pred = brf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('LOGREG') # Logarythmic Regression\n",
    "\n",
    "logreg = LogisticRegression(random_state = 53)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('XGB') # Extreme Gradient Boosting\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('KNN') # K-Nearest Neighbors Algorithm \n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Gaussian') # Gaussian Mixture\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7QTJE6oxKPXB",
   "metadata": {
    "id": "7QTJE6oxKPXB"
   },
   "outputs": [],
   "source": [
    "# Final check of feature importance.\n",
    "\n",
    "importances = list(rf.feature_importances_)\n",
    "col_labels = x_data.columns.values.tolist()\n",
    "\n",
    "dict_test = {\"label\":col_labels,\"importances\":importances}\n",
    "\n",
    "df_test = pd.DataFrame(dict_test, columns=['label','importances'])\n",
    "\n",
    "df_test['importances'] = df_test['importances'] * 100\n",
    " \n",
    "df_test.sort_values(by=['importances'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db043f0b-9901-40c8-85d3-14500963a7f3",
   "metadata": {
    "id": "db043f0b-9901-40c8-85d3-14500963a7f3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
